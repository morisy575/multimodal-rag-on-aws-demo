{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae9596ef-0f60-494b-83d0-5827f2a099f9",
   "metadata": {},
   "source": [
    "# ハンズオン：Multimodal RAG on AWS を構築してみよう"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995ef3cd-5494-497d-9f97-dd06fc535ced",
   "metadata": {},
   "source": [
    "## 0. 事前準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a2aa04-1253-4190-9f64-43307157e603",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -U pip\n",
    "%pip install opensearch-py boto3 opencv-python PyMuPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9caf06ce-431c-48a2-8379-930cbc625408",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "\n",
    "bedrock_runtime_client = boto3.client('bedrock-runtime',region_name='us-east-1')\n",
    "s3_client = boto3.client('s3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9172e9-94ca-43b8-983c-3423ae42f20f",
   "metadata": {},
   "source": [
    "## 1. Amazon Bedrock の API を叩いてみる"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b288d81a-b731-457c-a9f5-1cdcd69d42c9",
   "metadata": {},
   "source": [
    "- 2024 年5月時点で、Amazon Bedrock では 30 以上の基盤モデルを API 経由で利用することができます。テキスト生成モデルや画像生成モデル、テキスト & ビジョンモデルなど様々な種類があります。\n",
    "- 様々な基盤モデルを　InvokeModel API という1つの API を通して利用することができます。使用したいモデルの ModelId を指定し、プロンプトやその他パラメータを指定します。\n",
    "- 利用可能なモデルと ModelID の一覧は[こちらのドキュメント](https://docs.aws.amazon.com/bedrock/latest/userguide/model-ids.html#model-ids-arns) をご覧ください。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2011df0e-a9ea-4e64-9df6-2af7cc58ec21",
   "metadata": {},
   "source": [
    "#### テキスト生成モデル\n",
    "今回はテキスト生成モデルである Anthropic Claude 3 Sonnet を使います。後述するように、Claude 3 は画像も同時に入力することができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca99b050-3c04-4a81-bf4a-00ff787b2065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# テキスト & ビジョンモデルである Anthropic Claude 3 Sonnet を使います。\n",
    "def invoke_llm_model(input):\n",
    "    user_message = {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": input,\n",
    "            }\n",
    "        ],\n",
    "    }\n",
    "    messages = [user_message]\n",
    "    body = json.dumps(\n",
    "        {\n",
    "            \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "            \"max_tokens\": 4096,\n",
    "            \"messages\": messages,\n",
    "            \"temperature\": 0,\n",
    "            \"top_p\": 1,\n",
    "            \"top_k\": 250,\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    modelId=\"anthropic.claude-3-sonnet-20240229-v1:0\"\n",
    "    accept = \"application/json\"\n",
    "    contentType = \"application/json\"\n",
    "    \n",
    "    response = bedrock_runtime_client.invoke_model(\n",
    "            body=body, modelId=modelId, accept=accept, contentType=contentType\n",
    "    )\n",
    "    response_body = json.loads(response.get(\"body\").read().decode())\n",
    "    return response_body.get(\"content\")[0][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0ee8ef-06b4-47ce-ace9-b9df667f9166",
   "metadata": {},
   "outputs": [],
   "source": [
    "invoke_llm_model(\"大阪の有名な観光地をコテコテの関西弁で教えて\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a937b1f9-97ae-4a87-a30e-d15910913b3c",
   "metadata": {},
   "source": [
    "#### 埋め込みモデル\n",
    "Embedding Model として Cohere 社の Multilingual Embed モデルを使用します。\n",
    "その他の基盤モデルには Amazon Titan Embedding などがあります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07df3036-a2aa-4c9d-a303-ba79e55b98cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def invoke_embedding_model(input):\n",
    "    response = bedrock_runtime_client.invoke_model(\n",
    "        body=json.dumps({\n",
    "            'texts': input,\n",
    "            'input_type': 'search_document'\n",
    "        }),\n",
    "        modelId = 'cohere.embed-multilingual-v3',\n",
    "        accept=\"application/json\",\n",
    "        contentType=\"application/json\",\n",
    "    )\n",
    "    response_body = json.loads(response.get(\"body\").read())\n",
    "    return response_body.get(\"embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ca4485-b9a5-44ee-b9eb-01f1b8fe5efa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "invoke_embedding_model([\"こんにちは\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af02cf67-254b-47c8-9047-0b8746fd241d",
   "metadata": {},
   "source": [
    "#### Image Captioning\n",
    "Anthropic Claude 3 は テキスト & ビジョンモデルであり、画像とテキストを同時に入力することができます。それにより画像に描かれている内容の記述や、画像内に含まれるテキスト・数値の抽出などの用途に用いることができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7212ff2a-1272-4edd-be3e-ca29459583f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "\n",
    "# Bedrock の API に渡すために画像を Base64 文字列にエンコードする関数\n",
    "def encode_image(img_file):\n",
    "    with open(img_file, \"rb\") as image_file:\n",
    "        img_str = base64.b64encode(image_file.read())\n",
    "        base64_string = img_str.decode(\"latin1\")\n",
    "    return base64_string\n",
    "\n",
    "# Claude 3 を用いて画像からキャプションを生成させる関数\n",
    "def generate_image_captions(img_base64, prompt=\"あなたは画像を分析するタスクを担うアシスタントです。以下に与える画像データについて、画像中に存在する文字列や数値をできるだけ多く使いながら、詳細に分析してください。\"): \n",
    "\n",
    "    max_tokens = 4096\n",
    "    user_message = {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"image\",\n",
    "                    \"source\": {\n",
    "                        \"type\": \"base64\",\n",
    "                        \"media_type\": \"image/png\",\n",
    "                        \"data\": img_base64\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": prompt\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    \n",
    "    \n",
    "    messages = [user_message]\n",
    "    model_id=\"anthropic.claude-3-sonnet-20240229-v1:0\"\n",
    "    body = json.dumps(\n",
    "        {\n",
    "            \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "            \"max_tokens\": max_tokens,\n",
    "            \"messages\": messages,\n",
    "            \"temperature\": 0\n",
    "        }\n",
    "    )\n",
    "    response = bedrock_runtime_client.invoke_model(body=body, modelId=model_id)\n",
    "    response_body = json.loads(response.get('body').read())\n",
    "    return response_body['content'][0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1750e4-0340-41fa-b31f-213c4b7e22e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "img_path = \"claude3-family-comparison.png\"\n",
    "fig = Image.open(img_path)\n",
    "fig.show()\n",
    "print(generate_image_captions(encode_image(img_path)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a2fefb-67f0-439d-89be-75843ca773f3",
   "metadata": {},
   "source": [
    "### 参考：LangChain を用いる場合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27afe598-c0a8-4833-afd3-ad725e2d0ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import BedrockChat\n",
    "\n",
    "def invoke_llm_model_langchain(prompt):\n",
    "    llm = BedrockChat(\n",
    "        model_id=\"anthropic.claude-3-sonnet-20240229-v1:0\", \n",
    "        client=bedrock_runtime_client,\n",
    "        model_kwargs={'temperature': 0.5, \"top_p\": 1, \"top_k\": 250}\n",
    "    )\n",
    "    answer = llm.invoke(prompt)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c95ae50-c663-4c48-b87b-945fc99c96c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "invoke_llm_model_langchain(\"味噌汁の作り方を詳しく説明してください。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d25e00a-12ea-425e-91e3-3973f1ec9943",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import BedrockEmbeddings\n",
    "\n",
    "def invoke_embedding_model_langchain(prompt):\n",
    "    embedding_model = BedrockEmbeddings(\n",
    "        client=bedrock_runtime_client,\n",
    "        model_id = 'cohere.embed-multilingual-v3'\n",
    "    )\n",
    "    answer = embedding_model.embed_query(prompt)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c9808f-00b8-4b17-a3e2-9f26339e66fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "invoke_embedding_model_langchain(\"こんにちは\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb05b67-7ed8-4442-a9c7-ae84b88f06a7",
   "metadata": {},
   "source": [
    "## 2. RAG 用データの準備\n",
    "ここから Multimodal RAG の実装に向かっていきます。まずはナレッジベースとしてベクトル DB にIngest するドキュメントを準備します。\n",
    "\n",
    "今回は PDF ファイルを対象としたマルチモーダル RAG を実装していきます。\n",
    "\n",
    "`./documents`フォルダに PDF ファイルを格納してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5e2d24-0d99-4503-b142-bcfe987aa979",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "data_dir = './documents'\n",
    "target_files = sorted([os.path.join(data_dir,file_name) for file_name in os.listdir(data_dir)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0965e7-f3b6-4ecf-8cea-0a78cd84a099",
   "metadata": {},
   "source": [
    "## 3. Extract elements via PyMuPDF and Process PDF files\n",
    "PyMuPDF (fitz) というライブラリは、PDF ファイルをテキスト、表、画像等の要素に分解することができるライブラリです。\n",
    "`./documents`フォルダ下の PDF ファイルを PyMuPDF で解析していき、各要素をRAG で検索できるような形に変換していきます。\n",
    "\n",
    "補足： そのほかのライブラリとして、`unstructured`([GitHub](https://github.com/Unstructured-IO/unstructured))を用いることで Excel ファイルや Powerpoint ファイルを扱うことができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9793c6e8-e577-4a7b-a39d-d5238fee5edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_output_dir = \"./image_output/\"\n",
    "os.makedirs(image_output_dir, exist_ok=True) \n",
    "\n",
    "bucket = \"<Input yout bucket name>\"\n",
    "common_prefix = \"multimodal-rag-workshop\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121afdb0-6b89-44f9-9f32-8cccc4660abc",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import fitz\n",
    "from pprint import pprint\n",
    "import re, io\n",
    "from PIL import Image\n",
    "\n",
    "table_llm_prompt = \"\"\"\n",
    "<instruction>あなたは表を分析するタスクを担うアシスタントです。以下に与える表データについて、下記に記載されている出力項目に着目して読み取れることを出力してください。</instruction>\n",
    "<content>\n",
    "- 何がまとめられている表なのか\n",
    "- 表に記載されているキーワード\n",
    "- 表から読み取ることができる分析結果\n",
    "</content>\n",
    "<table> {table} </table>\n",
    "\"\"\"\n",
    "\n",
    "image_llm_prompt = \"\"\"\n",
    "あなたは画像を分析するタスクを担うアシスタントです。以下に与える画像データについて、画像中に存在する文字列や数値をできるだけ多く使いながら、詳細に分析してください。\n",
    "\"\"\"\n",
    "\n",
    "# 簡単のため1000文字ごとにチャンクを区切ることとします\n",
    "chunk_interval =  1000\n",
    "\n",
    "# 解析した結果を格納するリスト\n",
    "extracted_elements_list = []\n",
    "\n",
    "for target_file in target_files:\n",
    "    \n",
    "    filename = target_file.split('/')[-1]\n",
    "    filename_base = filename.split('.')[0]\n",
    "    src_doc = \"multimodal-rag-workshop/documents/\"+filename\n",
    "    s3_client.upload_file(target_file, bucket, src_doc)\n",
    "    \n",
    "    doc = fitz.open(target_file)\n",
    "    \n",
    "    tables = []\n",
    "    texts = []\n",
    "    image_captions = []\n",
    "    for page_index, page in enumerate(doc):\n",
    "        \n",
    "        text = page.get_text()\n",
    "        text = re.sub(r'(?<! )\\n(?! )', ' ', text)\n",
    "\n",
    "        split_text = [text[x:x+chunk_interval] for x in range(0, len(text), chunk_interval)]\n",
    "        texts.extend(split_text)\n",
    "\n",
    "        \n",
    "        tabs = page.find_tables()\n",
    "        if tabs.tables:\n",
    "            for table_index, table in enumerate(tabs):\n",
    "                df = table.to_pandas()\n",
    "                rows, columns = df.shape\n",
    "                print(df)\n",
    "                null_percentage = (df[(df=='')].count().sum() + df.isnull().sum().sum())/df.size\n",
    "                if rows < 2 or columns < 2 or null_percentage >= 0.3:\n",
    "                    continue\n",
    "                tables.append({'raw':str(table.extract()), 'summary':invoke_llm_model(table_llm_prompt.format(table=table.extract()))})\n",
    "\n",
    "                \n",
    "        images = page.get_images()\n",
    "        \n",
    "        if images:\n",
    "            for image_index, img in enumerate(images):\n",
    "                xref = img[0]\n",
    "                img_info = doc.extract_image(xref)\n",
    "                if img_info['width'] < 256 or img_info['height'] < 256:\n",
    "                    continue\n",
    "                image_data = img_info[\"image\"]\n",
    "                image_ext = img_info[\"ext\"]\n",
    "\n",
    "                pil_img = Image.open(io.BytesIO(image_data))\n",
    "                image_output_filename = filename_base + \"_page\" + f'{page_index:03d}' + \"_\" + f'{image_index:03d}' + '.png'\n",
    "                image_output_path = image_output_dir + image_output_filename\n",
    "                pil_img.save(image_output_path, format = \"PNG\")\n",
    "                \n",
    "                # バイナリストリームに変換\n",
    "                buffered = io.BytesIO()\n",
    "                pil_img.save(buffered, format=\"PNG\")\n",
    "                img_str = base64.b64encode(buffered.getvalue()).decode()\n",
    "\n",
    "                try:\n",
    "                    caption = generate_image_captions(img_str, prompt = image_llm_prompt)\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "                # 抽出された画像は Amazon S3 にアップロード\n",
    "                output_img_s3_path = \"multimodal-rag-workshop/images/\"+image_output_filename\n",
    "                s3_client.upload_file(image_output_path, bucket, output_img_s3_path)\n",
    "                \n",
    "                image_captions.append({'s3_path': output_img_s3_path, 'caption': caption})\n",
    "        \n",
    "    extracted_elements_list.append({\n",
    "        'source': src_doc,\n",
    "        'tables': tables,\n",
    "        'texts': texts,\n",
    "        'images': image_captions\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0220968e-304f-4653-a676-5756bb281387",
   "metadata": {},
   "source": [
    "## 4. ベクトル DB として OpenSearch Serverless を構築する\n",
    "ベクトル DB の実装方式として、ChromaDB等を用いてアプリと同居する形で構築する方式もありますが、実用的には、アプリと切り出した外部DBを用いることが望ましいです。\n",
    "今回は、　ベクトルデータベースとして Amazon OpenSearch Serverless を使用します。ユーザー側でのインフラ管理不要、処理増減に合わせて自動でスケールするマネージドサービスです。\n",
    "\n",
    "ここでは、先ほど抽出した各要素を Embedding モデルを用いてベクトル化し、Amazon OpenSearch Serverless (aoss) に格納していきます。\n",
    "ドキュメントの数が大量になった場合は Amazon Bedrock の [バッチ推論機能](https://docs.aws.amazon.com/bedrock/latest/userguide/batch-inference.html) を用いる方法もあります。ただ、今回はドキュメントの数がそこまで多くないため、利用せずシンプルな推論方式で実行します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927876d0-9491-4958-80a3-6e39d4e1d806",
   "metadata": {},
   "outputs": [],
   "source": [
    "####\n",
    "#### 準備：マネージメントコンソール経由で Amazon OpenSearch Serverless コレクションを作成してください。\n",
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e954598-5816-4a1d-80f7-86b0af6a2a73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from opensearchpy import OpenSearch, RequestsHttpConnection, AWSV4SignerAuth\n",
    "session = boto3.Session()\n",
    "host = '<input your aoss endpoint>' # https は抜く\n",
    "region = 'ap-northeast-1'\n",
    "service = 'aoss'\n",
    "credentials = session.get_credentials()\n",
    "auth = AWSV4SignerAuth(credentials, region, service)\n",
    "\n",
    "os_client = OpenSearch(\n",
    "    hosts = [{'host': host, 'port': 443}],\n",
    "    http_auth = auth,\n",
    "    use_ssl = True,\n",
    "    verify_certs = True,\n",
    "    connection_class = RequestsHttpConnection,\n",
    "    pool_maxsize = 20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e57b738-a09e-4f1c-bacd-d7ca09204d41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prep_document(embedding,raw_element,processed_element,doc_type,src_doc, s3_bucket, image_s3_path):\n",
    "    document = { \n",
    "        # \"_id\": str(hash(raw_element)),\n",
    "        \"processed_element_embedding\": embedding,\n",
    "        \"processed_element\": processed_element,\n",
    "        \"raw_element_type\": doc_type,\n",
    "        \"raw_element\": raw_element,\n",
    "        \"src_doc\": src_doc,\n",
    "        \"s3_bucket\": s3_bucket,\n",
    "        \"image_s3_path\": image_s3_path\n",
    "    }\n",
    "    return document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6b1089-bc04-4e4c-80ca-2f7ecd0e9345",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "index_name = \"rag_index\"\n",
    "\n",
    "index_body = \"\"\"\n",
    "{\n",
    "  \"settings\": {\n",
    "    \"index.knn\": true\n",
    "  },\n",
    "  \"mappings\": {\n",
    "    \"properties\": {\n",
    "      \"processed_element_embedding\": {\n",
    "        \"type\": \"knn_vector\",\n",
    "        \"dimension\": 1024,\n",
    "        \"method\": {\n",
    "          \"name\": \"hnsw\",\n",
    "          \"engine\": \"faiss\",\n",
    "          \"parameters\": {}\n",
    "        }\n",
    "      },\n",
    "      \"src_doc\": {\n",
    "        \"type\": \"text\"\n",
    "      },\n",
    "      \"raw_element\": {\n",
    "        \"type\": \"text\"\n",
    "      },\n",
    "      \"raw_element_type\": {\n",
    "        \"type\": \"text\"\n",
    "      },\n",
    "      \"processed_element\": {\n",
    "        \"type\": \"text\"\n",
    "      },\n",
    "      \"s3_bucket\": {\n",
    "        \"type\": \"text\"\n",
    "      },\n",
    "      \"image_s3_path\": {\n",
    "        \"type\": \"text\"\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "index_body = json.loads(index_body)\n",
    "\n",
    "response = os_client.indices.create(index_name, body=index_body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc57d81-1930-4f6b-94f2-da0e4a6fa943",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "documents = []\n",
    "for extracted_element in extracted_elements_list:\n",
    "    texts = extracted_element['texts']\n",
    "    tables = extracted_element['tables']\n",
    "    image_captions = extracted_element['images']\n",
    "    src_doc = extracted_element['source']\n",
    "\n",
    "    for i,text in enumerate(texts):\n",
    "        embedding = invoke_embedding_model([text])[0]\n",
    "        document = prep_document(embedding,text,text,'text',src_doc, bucket, \"\")\n",
    "        documents.append(document)\n",
    "    \n",
    "    for table in tables:\n",
    "        table_raw = table['raw']\n",
    "        table_summary = table['summary']\n",
    "        embedding = invoke_embedding_model([table_summary])[0]\n",
    "        document = prep_document(embedding,table_raw,table_summary,'table',src_doc, bucket, \"\")\n",
    "        documents.append(document)\n",
    "        \n",
    "    for image_caption in image_captions:\n",
    "        embedding = invoke_embedding_model([image_caption['caption']])[0]\n",
    "        document = prep_document(embedding,image_caption['caption'],image_caption['caption'],'image',src_doc, bucket, image_caption['s3_path'])\n",
    "        documents.append(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e598cb-7bb3-43ae-a48c-ca8fb602b573",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for doc in documents:\n",
    "    response = os_client.index(\n",
    "        index = index_name,\n",
    "        body = doc,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aaac9a9-5640-43a9-a609-0d2e334317c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'Claude 3 はいつ発表されましたか？'\n",
    "embedding = invoke_embedding_model([question])[0]\n",
    "k = 3 # number of neighbours, size and k are the same to return k results in total. If size is not specified, k results will be returned per shard.\n",
    "query = {\n",
    "    \"size\": k,\n",
    "    \"query\": {\n",
    "        \"knn\": {\n",
    "            \"processed_element_embedding\": {\n",
    "                \"vector\": embedding, \n",
    "                \"k\": k}\n",
    "            },\n",
    "    }\n",
    "}\n",
    "\n",
    "response = os_client.search(\n",
    "    body = query,\n",
    "    index = index_name\n",
    ")\n",
    "\n",
    "hits = response['hits']['hits']\n",
    "prompt_template = \"\"\"\n",
    "    The following is a friendly conversation between a human and an AI. \n",
    "    The AI is talkative and provides lots of specific details from its context.\n",
    "    If the AI does not know the answer to a question, it truthfully says it \n",
    "    does not know.\n",
    "    {context}\n",
    "    Instruction: Based on the above documents, provide a detailed answer for, {question} Answer \"don't know\" \n",
    "    if not present in the document. 出力は日本語でわかりやすく回答してください。\n",
    "    Solution:\"\"\"\n",
    "context = []\n",
    "for hit in hits:\n",
    "    context.append(hit['_source']['processed_element'])\n",
    "\n",
    "llm_prompt = prompt_template.format(context='\\n'.join(context),question=question)\n",
    "output = invoke_llm_model(llm_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6b12ab-2428-47e8-bd6a-1a911e11216e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(output)\n",
    "print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2743ea95-5cdf-4ce4-8146-3067b6b99263",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
